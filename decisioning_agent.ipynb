{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYWem0DPR4yJApQwdIXW1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinjaljoshi/ma_rag_components/blob/master/decisioning_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code to show routing based upon Object routing registry"
      ],
      "metadata": {
        "id": "nsleyGa5PmI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "-Q6GACqQNIci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FnPvIMDSKCZD"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# === Object Routing Registry ===\n",
        "object_routing_registry = {\n",
        "    \"purchase_order\": {\n",
        "        \"access_method\": \"api\",\n",
        "        \"endpoint\": \"/api/purchase-orders\"\n",
        "    },\n",
        "    \"purchase_order_status\": {\n",
        "        \"access_method\": \"api\",\n",
        "        \"endpoint\": \"/api/purchase-orders/status\"\n",
        "    },\n",
        "    \"__default__\": {\n",
        "        \"access_method\": \"sql\"\n",
        "    }\n",
        "}\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "# === Prompt Template ===\n",
        "routing_prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are a smart assistant helping route user queries to backend services.\n",
        "Given the following list of objects with access methods:\n",
        "\n",
        "{object_descriptions}\n",
        "\n",
        "Determine the best matching object for this user query:\n",
        "\"{user_query}\"\n",
        "\n",
        "Respond only with the exact object name from the list above, or \"__default__\" if nothing matches.\n",
        "\"\"\")\n",
        "\n",
        "# === LLM Setup ===\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "routing_chain = LLMChain(llm=llm, prompt=routing_prompt)\n",
        "\n",
        "# === Helper Function: Convert Registry to Input String ===\n",
        "def format_object_descriptions(routing_registry: dict) -> str:\n",
        "    descriptions = []\n",
        "    for name, conf in routing_registry.items():\n",
        "        if name == \"__default__\":\n",
        "            descriptions.append(f\"- {name} (fallback if no match)\")\n",
        "        else:\n",
        "            endpoint = conf.get(\"endpoint\", \"N/A\")\n",
        "            method = conf.get(\"access_method\", \"unknown\")\n",
        "            descriptions.append(f\"- {name} (access_method: {method}, endpoint: {endpoint})\")\n",
        "    return \"\\n\".join(descriptions)\n",
        "\n",
        "# === Manager Agent Routing Logic Using LLM ===\n",
        "def manager_routing_logic_llm(query: str) -> str:\n",
        "    object_descriptions = format_object_descriptions(object_routing_registry)\n",
        "    response = routing_chain.run({\n",
        "        \"object_descriptions\": object_descriptions,\n",
        "        \"user_query\": query\n",
        "    }).strip()\n",
        "    print(f\" LLM selected method: {response}\")\n",
        "    return object_routing_registry.get(response, object_routing_registry[\"__default__\"])[\"access_method\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_1 = \"What's the status of my purchase orders?\"\n",
        "print(\"Access method:\", manager_routing_logic_llm(query_1))\n",
        "\n",
        "query_2 = \"Summarize sales by region\"\n",
        "print(\"Access method:\", manager_routing_logic_llm(query_2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ5Mx8-zPUV_",
        "outputId": "3f6427b5-3fcb-435f-82bc-c8bb1b08649e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LLM selected method: purchase_order_status\n",
            "Access method: api\n",
            " LLM selected method: __default__\n",
            "Access method: sql\n"
          ]
        }
      ]
    }
  ]
}