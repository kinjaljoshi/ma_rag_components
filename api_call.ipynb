{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl2PwKDBpR1YYb0/yab4CM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinjaljoshi/ma_rag_components/blob/master/api_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "X1D_WOCUVxS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aXHPx4r4VYr8"
      },
      "outputs": [],
      "source": [
        "# Extended API object registry\n",
        "api_registry = {\n",
        "    \"purchase_order\": {\n",
        "        \"access_method\": \"api\",\n",
        "        \"endpoint\": \"/api/purchase-orders\",\n",
        "        \"params\": [\"po_id\", \"vendor_id\"]\n",
        "    },\n",
        "    \"sales_order\": {\n",
        "        \"access_method\": \"api\",\n",
        "        \"endpoint\": \"/api/sale-orders\",\n",
        "        \"params\": [\"order_id\"]\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "api_call_prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are a smart assistant that helps generate Python function calls to invoke APIs.\n",
        "\n",
        "Here is the available API registry with parameters:\n",
        "\n",
        "{api_descriptions}\n",
        "\n",
        "User query:\n",
        "\"{user_query}\"\n",
        "\n",
        "Generate a Python function call in this format:\n",
        "call_api(<object_name>, <parameter_dict>)\n",
        "\n",
        "Respond with **only the function call**.\n",
        "\"\"\")\n",
        "\n",
        "def format_api_descriptions(registry):\n",
        "    lines = []\n",
        "    for name, conf in registry.items():\n",
        "        params = \", \".join(conf.get(\"params\", []))\n",
        "        lines.append(f\"- {name}: endpoint={conf['endpoint']}, params=[{params}]\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "api_chain = LLMChain(llm=llm, prompt=api_call_prompt)\n",
        "\n",
        "def generate_api_function_call(user_query: str):\n",
        "    descriptions = format_api_descriptions(api_registry)\n",
        "    response = api_chain.run({\n",
        "        \"api_descriptions\": descriptions,\n",
        "        \"user_query\": user_query\n",
        "    })\n",
        "    return response.strip()\n",
        "def call_api(object_name: str, params: dict):\n",
        "    endpoint = api_registry[object_name][\"endpoint\"]\n",
        "    print(f\"Calling API: {endpoint}\")\n",
        "    print(f\"With parameters: {params}\")\n"
      ],
      "metadata": {
        "id": "KA_Hli5uVtfy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Get purchase orders for vendor V-1234\"\n",
        "\n",
        "func_call = generate_api_function_call(query)\n",
        "print(\"LLM Function Call:\", func_call)\n",
        "\n",
        "exec(func_call)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HBtmsV3WpI9",
        "outputId": "1cb81421-0c14-4b1d-b7e6-7ba3131bcd1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-f82010c306f9>:40: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = api_chain.run({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Function Call: call_api('purchase_order', {'vendor_id': 'V-1234'})\n",
            "Calling API: /api/purchase-orders\n",
            "With parameters: {'vendor_id': 'V-1234'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Get sales orders details for order X-9999\"\n",
        "\n",
        "func_call = generate_api_function_call(query)\n",
        "print(\"LLM Function Call:\", func_call)\n",
        "\n",
        "exec(func_call)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQsF-Do-W1SS",
        "outputId": "ee3c97d3-dcb1-457c-a9ee-f543ded0616c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Function Call: call_api('sales_order', {'order_id': 'X-9999'})\n",
            "Calling API: /api/sale-orders\n",
            "With parameters: {'order_id': 'X-9999'}\n"
          ]
        }
      ]
    }
  ]
}